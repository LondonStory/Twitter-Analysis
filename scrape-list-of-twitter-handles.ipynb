{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installs and imports"
      ],
      "metadata": {
        "id": "mniozxm-imoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install --upgrade -e git+https://github.com/twintproject/twint.git@origin/master#egg=twint\n",
        "#!python3 -m pip install twint\n",
        "!pip install twint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKvYp42rihlp",
        "outputId": "745c96b3-3250-4528-ec3b-831eddc99df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: twint in ./src/twint (2.1.21)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from twint) (3.8.3)\n",
            "Requirement already satisfied: aiodns in /usr/local/lib/python3.8/dist-packages (from twint) (3.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from twint) (4.6.3)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.8/dist-packages (from twint) (2.1.7)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.8/dist-packages (from twint) (0.6)\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.8/dist-packages (from twint) (8.6.1)\n",
            "Requirement already satisfied: pysocks in /usr/local/lib/python3.8/dist-packages (from twint) (1.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from twint) (1.3.5)\n",
            "Requirement already satisfied: aiohttp_socks in /usr/local/lib/python3.8/dist-packages (from twint) (0.7.1)\n",
            "Requirement already satisfied: schedule in /usr/local/lib/python3.8/dist-packages (from twint) (1.1.0)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.8/dist-packages (from twint) (1.17.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.8/dist-packages (from twint) (1.1.1)\n",
            "Requirement already satisfied: googletransx in /usr/local/lib/python3.8/dist-packages (from twint) (2.4.2)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from aiodns->twint) (4.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->twint) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->twint) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->twint) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->twint) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->twint) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->twint) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->twint) (2.1.1)\n",
            "Requirement already satisfied: python-socks[asyncio]<3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp_socks->twint) (2.1.1)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.8/dist-packages (from elasticsearch->twint) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=5.0 in /usr/local/lib/python3.8/dist-packages (from fake-useragent->twint) (5.10.2)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.8/dist-packages (from geopy->twint) (1.52)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from googletransx->twint) (2.25.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->twint) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas->twint) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->twint) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from elastic-transport<9,>=8->elasticsearch->twint) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.8/dist-packages (from elastic-transport<9,>=8->elasticsearch->twint) (1.26.14)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=5.0->fake-useragent->twint) (3.12.1)\n",
            "Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pycares>=4.0.0->aiodns->twint) (1.15.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->twint) (1.15.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp->twint) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->googletransx->twint) (4.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns->twint) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgx-KlkOpKdy",
        "outputId": "4766216a-1665-4638-b297-a89cf3407bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.8/dist-packages (1.5.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "BxYTEeDRjrwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIrnKE-giMer"
      },
      "outputs": [],
      "source": [
        "import twint\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the dataset and extract usernames"
      ],
      "metadata": {
        "id": "LVJ0E836kZ57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZoagYnJnj_l",
        "outputId": "dd6c3500-16f0-4bb8-cd5c-e54fedd71ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the CSV"
      ],
      "metadata": {
        "id": "p10ZvTJMlqPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv ('/content/drive/MyDrive/replies-larrouturou-annotated-botometer.csv')\n",
        "df = pd.read_csv ('/content/drive/MyDrive/replies-alviinaalametsa-annotated-botometer.csv')"
      ],
      "metadata": {
        "id": "v_WBRNNilRh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd-MR44LltCy",
        "outputId": "e3b16528-da4a-46c0-bf72-6ee53a9fe36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'conversation_id', 'created_at', 'date', 'timezone', 'place',\n",
              "       'tweet', 'language', 'hashtags', 'cashtags', 'user_id', 'user_id_str',\n",
              "       'username', 'name', 'day', 'hour', 'link', 'urls', 'photos', 'video',\n",
              "       'thumbnail', 'retweet', 'nlikes', 'nreplies', 'nretweets', 'quote_url',\n",
              "       'search', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
              "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
              "       'trans_dest', 'sentiment', 'annotator', 'annotation_id', 'updated_at',\n",
              "       'lead_time', 'botometerCapEng.score', 'botometerCapUni.score',\n",
              "       'botometerOverallRawEng.score', 'botometerOverallRawUni.score',\n",
              "       'botometerDisplayEng.score', 'botometerDisplayUni.score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extract usernames of potentially bot accounts"
      ],
      "metadata": {
        "id": "wc4ego_ol3hN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bot = df[df['botometerOverallRawUni.score'] > 0.6]"
      ],
      "metadata": {
        "id": "Wy8IE9_Sl7D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop duplicates"
      ],
      "metadata": {
        "id": "mh9DBCVQnXOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bot_unique = df_bot.drop_duplicates(subset=['username'])"
      ],
      "metadata": {
        "id": "l8wo17BQnPIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to a list"
      ],
      "metadata": {
        "id": "nqcLmy8MoGM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "username_list_bot = df_bot_unique ['username'].tolist()\n",
        "print(len(username_list_bot))\n",
        "print (username_list_bot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anVf0YC-l1qa",
        "outputId": "e8f8503b-7e42-48ab-e441-3a6d8a4d4483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "['vt82878', 'sanjuktaroyvai1', 'ambar_dave', 'nameshakehe', 'SanatanForce', 'vedalasrinivas2', 'kirudevadiga', 'PunctureWalIa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extract usernames of 100% authentic/ real accounts"
      ],
      "metadata": {
        "id": "CnXuy2gtntdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_real = df[df['botometerOverallRawUni.score'] < 0.1]"
      ],
      "metadata": {
        "id": "YQQN1TnWn0sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop duplicates"
      ],
      "metadata": {
        "id": "WoWAWg2_oDHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_real_unique = df_real.drop_duplicates(subset=['username'])"
      ],
      "metadata": {
        "id": "8jqUv8Ven9H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to a list"
      ],
      "metadata": {
        "id": "5jBXcV2bx47u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "username_list_real = df_real_unique ['username'].tolist()\n",
        "print(len(username_list_real))\n",
        "print (username_list_real)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N6GVwQVoJdF",
        "outputId": "556153c6-a638-47bb-f636-2765c190ae89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n",
            "['tarunsharma005', 'ShekharrG', 'Sunishen', 'khab33b', 'IndiaFirst2022', 'bhanuvarma007', 'Ksharkhowa', 'tarunlalan', 'roshovani', 'pairamblr', 'tellitaly', 'spandakarika108', 'MohanKumarL11', 'Nishwins1', 'abhiawakes', 'niranjan_shaha', 'dcemeterygirl', 'UnApologeticM1', 'citizenNA', 'Prasenjit97m', 'AkashD60789383', 'Arjun_S_R', 'dschamyal', 'ScorpionHere', 'PrasadSatya10', 'VickyHanumant', 'woke_less', 'ib4uanytime', 'SachinDPatange', 'DiVpops', 'MiFe007', 'bhattketan1468', '_hamza_iftikhar', 'Hilale_pakistan', 'DrBharatbhushan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data acquisition function"
      ],
      "metadata": {
        "id": "bf2MKkLgir2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out [Twint's Github page](https://github.com/twintproject/twint) for more details.\n",
        "\n",
        "\n",
        "\n",
        "> See the [configuration](https://github.com/twintproject/twint/wiki/Configuration) page at Twint wiki page for more info on the the parameters to be set in specific scraping functions."
      ],
      "metadata": {
        "id": "SS3AyM8HtFtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_acq_search (user_name, num, since_date, until_date):\n",
        "    print (\"======================================\")\n",
        "    print(\":: Acquiring Data for\", user_name, \"::\")\n",
        "    print (\"======================================\")\n",
        "\n",
        "    # Configure\n",
        "    c = twint.Config()\n",
        "\n",
        "    #c.Search = search_string    # uncomment this if you want to scrape using a search_string, and provide this as the input of this function\n",
        "    c.Username = user_name\n",
        "\n",
        "    c.Since = since_date\n",
        "    c.Until = until_date\n",
        "\n",
        "    c.Limit = num\n",
        "\n",
        "    #c.Lang = 'nl'\n",
        "    #c.Translate = True \n",
        "    #c.TranslateDest = \"en\"\n",
        "\n",
        "    c.Store_object =  True\n",
        "    c.User_full = True\n",
        "    c.Profile_full = True\n",
        "    c.Show_hashtags = True\n",
        "    c.Hide_output = True\n",
        "\n",
        "    c.Pandas = True\n",
        "    twint.run.Search(c)\n",
        "\n",
        "    return twint.storage.panda.Tweets_df"
      ],
      "metadata": {
        "id": "xRpcri8lirfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== redundant function =====\n",
        "# ===== the call breaks due to JSON error on the Twint end ==== \n",
        "\n",
        "def data_acq_timeline (user_name, num, since_date, until_date):\n",
        "    print (\"======================================\")\n",
        "    print(\":: Acquiring Data for\", user_name, \"::\")\n",
        "    print (\"======================================\")\n",
        "\n",
        "    # Configure\n",
        "    c = twint.Config()\n",
        "\n",
        "    #c.Search = search_string    # uncomment this if you want to scrape using a search_string, and provide this as the input of this function\n",
        "    c.Username = user_name\n",
        "\n",
        "    c.Since = since_date\n",
        "    c.Until = until_date\n",
        "\n",
        "    c.Limit = num\n",
        "\n",
        "    #c.Lang = 'nl'\n",
        "    #c.Translate = True \n",
        "    #c.TranslateDest = \"en\"\n",
        "\n",
        "    c.Store_object =  True\n",
        "    c.User_full = True\n",
        "    c.Profile_full = True\n",
        "    c.Hide_output = True\n",
        "\n",
        "    c.Pandas = True\n",
        "    twint.run.Profile(c)\n",
        "\n",
        "    return twint.storage.panda.Tweets_df"
      ],
      "metadata": {
        "id": "ejcPjGQwjrH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameters to acquire tweets"
      ],
      "metadata": {
        "id": "pki5EVnEmFII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# provide the list of usernames\n",
        "\n",
        "#----larrouturou-----\n",
        "#username_list = username_list_bot\n",
        "#username_list = list (set(username_list_real) - set(['mrImteyaz8','TheWhiteWaIker','frankblunt2021', 'maverick9762', 'dinakar24', 'Prasenjit97m', 'omprakash2711']))\n",
        "\n",
        "\n",
        "#----alviinaalametsa----\n",
        "#username_list = username_list_bot\n",
        "username_list = list (set(username_list_real) - set(['spandakarika108', 'Prasenjit97m']))\n",
        "\n",
        "\n",
        "# provide the number of most recent tweets you want to scrape\n",
        "N = 10000\n",
        "\n",
        "# provide the beginning date ('YYYY-MM-DD' format)\n",
        "since_date = '2018-01-01 12:00:00'\n",
        "\n",
        "# provide the end date\n",
        "until_date = '2023-01-01 12:00:00'"
      ],
      "metadata": {
        "id": "8HHhO_demHRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the scrapper function to extract the historical dataset and save"
      ],
      "metadata": {
        "id": "9cBsvnYum9ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (len(username_list)):\n",
        "  # run the scrapper function\n",
        "  feed_df = data_acq_search (str(username_list[i]), N, since_date, until_date)\n",
        "\n",
        "  # convert the output into a dataframe\n",
        "  df = pd.DataFrame (feed_df)\n",
        "\n",
        "  # print the head of the dataframe\n",
        "  print (df.head())\n",
        "\n",
        "  # save the dataframe as csv to your Google Drive -- \n",
        "  #================= CHANGE THE PATH BELOW ACCORDING TO THE SEARCH ABOVE==================\n",
        "\n",
        "  #df.to_csv ('/content/drive/My Drive/Twitter-Accounts-Historical-Data/Larrouturou/Bot/%s.csv' %username_list[i])\n",
        "  #df.to_csv ('/content/drive/My Drive/Twitter-Accounts-Historical-Data/Larrouturou/Real/%s.csv' %username_list[i])\n",
        "\n",
        "  #df.to_csv ('/content/drive/My Drive/Twitter-Accounts-Historical-Data/Alviinaalametsa/Bot/%s.csv' %username_list[i])\n",
        "  df.to_csv ('/content/drive/My Drive/Twitter-Accounts-Historical-Data/Alviinaalametsa/Real/%s.csv' %username_list[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu0hXXcnm6Gm",
        "outputId": "f3c30435-c543-4873-e733-2c4b89b7af4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================\n",
            ":: Acquiring Data for khab33b ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for Hilale_pakistan ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for Arjun_S_R ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1609245124894261249  1609236169438494722  1.672509e+12   \n",
            "1  1609242920007389190  1609009935144349696  1.672508e+12   \n",
            "2  1609029221896290310  1608056944501178368  1.672457e+12   \n",
            "3  1609026440095469569  1608735970131849217  1.672457e+12   \n",
            "4  1609025699167490049  1608788083448901634  1.672457e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-31 17:48:30    +0000         \n",
            "1  2022-12-31 17:39:45    +0000         \n",
            "2  2022-12-31 03:30:35    +0000         \n",
            "3  2022-12-31 03:19:32    +0000         \n",
            "4  2022-12-31 03:16:35    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0  @MarioNawfal What else has she done apart from...       en       []   \n",
            "1  @AsmaZehradr Illegal immigrants have no place ...       en       []   \n",
            "2  @Cobratate @GretaThunberg Apparently for the l...       en       []   \n",
            "3  @Chaos2Cured @MattWallace888 @GretaThunberg Wh...       en       []   \n",
            "4  @DimartinDi @David_Challen When will misandry ...       en       []   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0  [{'screen_name': 'MarioNawfal', 'name': 'Mario...                          \n",
            "1  [{'screen_name': 'AsmaZehradr', 'name': 'Asma ...                          \n",
            "2  [{'screen_name': 'Cobratate', 'name': 'Andrew ...                          \n",
            "3  [{'screen_name': 'Chaos2Cured', 'name': 'Kirk ...                          \n",
            "4  [{'screen_name': 'DimartinDi', 'name': 'di mar...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for pairamblr ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1609188570568310785  1609158789982453760  1.672495e+12   \n",
            "1  1609173891582156800  1608974445951213570  1.672492e+12   \n",
            "2  1609137183616823296  1608974445951213570  1.672483e+12   \n",
            "3  1609135355151937536  1608974445951213570  1.672483e+12   \n",
            "4  1608982622767833088  1608974445951213570  1.672446e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-31 14:03:47    +0000         \n",
            "1  2022-12-31 13:05:27    +0000         \n",
            "2  2022-12-31 10:39:35    +0000         \n",
            "3  2022-12-31 10:32:19    +0000         \n",
            "4  2022-12-31 00:25:25    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0  @zoo_bear Can u tell us Indians, what good thi...       en       []   \n",
            "1  @jogg39446862 @NeerajS66373657 @zoo_bear aapka...       hi       []   \n",
            "2  @NeerajS66373657 @zoo_bear 2/n Media job is to...       en       []   \n",
            "3  @NeerajS66373657 @zoo_bear absurdity limitless...       en       []   \n",
            "4  @zoo_bear Your tweet is NOT about either \"home...       en       []   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0  [{'screen_name': 'zoo_bear', 'name': 'Mohammed...                          \n",
            "1  [{'screen_name': 'jogg39446862', 'name': 'exse...                          \n",
            "2  [{'screen_name': 'NeerajS66373657', 'name': 'N...                          \n",
            "3  [{'screen_name': 'NeerajS66373657', 'name': 'N...                          \n",
            "4  [{'screen_name': 'zoo_bear', 'name': 'Mohammed...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for tarunlalan ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1607260014858891264  1606631010866958343  1.672036e+12   \n",
            "1  1606540497417560065  1606147745093505025  1.671864e+12   \n",
            "2  1606145457037533184  1605900623970549761  1.671770e+12   \n",
            "3  1605021649627402240  1604797125250142208  1.671502e+12   \n",
            "4  1604121009396686848  1604121009396686848  1.671287e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-26 06:20:23    +0000         \n",
            "1  2022-12-24 06:41:17    +0000         \n",
            "2  2022-12-23 04:31:32    +0000         \n",
            "3  2022-12-20 02:05:55    +0000         \n",
            "4  2022-12-17 14:27:06    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0  @thehawkeyex @MEAIndia @IndiaembFrance  https:...      qme       []   \n",
            "1  @anandmahindra @SerumInstIndia @BharatBiotech ...       en       []   \n",
            "2                                  @SJosephBurns WMD      und       []   \n",
            "3           @AndColorPockeT  https://t.co/CT0aTqUa8Y      qme       []   \n",
            "4                  The tweet that popped car bubble.       en       []   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0  [{'screen_name': 'thehawkeyex', 'name': 'The H...                          \n",
            "1  [{'screen_name': 'anandmahindra', 'name': 'ana...                          \n",
            "2  [{'screen_name': 'SJosephBurns', 'name': 'Stev...                          \n",
            "3  [{'screen_name': 'AndColorPockeT', 'name': 'ü¶Å'...                          \n",
            "4                                                 []                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for AkashD60789383 ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for UnApologeticM1 ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for woke_less ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for ib4uanytime ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1609510331365359619  1609177648496005120  1.672572e+12   \n",
            "1  1609116967520329729  1609079729042370561  1.672478e+12   \n",
            "2  1609115746730405888  1609081382160191490  1.672478e+12   \n",
            "3  1609081522363207680  1608974445951213570  1.672470e+12   \n",
            "4  1609077499945943052  1608876400286765059  1.672469e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2023-01-01 11:22:20    +0000         \n",
            "1  2022-12-31 09:19:15    +0000         \n",
            "2  2022-12-31 09:14:24    +0000         \n",
            "3  2022-12-31 06:58:24    +0000         \n",
            "4  2022-12-31 06:42:25    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0  @Aryan_warlord @PressTVPrograms Given the much...       en       []   \n",
            "1  @Aryan_warlord Hehehe....so the USA finds out ...       en       []   \n",
            "2  @Aryan_warlord OMG...seems the Infantry has no...       en       []   \n",
            "3  @zoo_bear Encroachment being removed post High...       en       []   \n",
            "4  @cvkrishnan Guam heavily fortified, PLAN will ...       en       []   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0  [{'screen_name': 'Aryan_warlord', 'name': 'Nin...                          \n",
            "1  [{'screen_name': 'Aryan_warlord', 'name': 'Nin...                          \n",
            "2  [{'screen_name': 'Aryan_warlord', 'name': 'Nin...                          \n",
            "3  [{'screen_name': 'zoo_bear', 'name': 'Mohammed...                          \n",
            "4  [{'screen_name': 'cvkrishnan', 'name': 'Krishn...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for niranjan_shaha ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for tellitaly ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1606772157794914304  1605399301072748544  1.671919e+12   \n",
            "1  1605640872183595009  1605480784743186432  1.671650e+12   \n",
            "2  1603959046499078144  1603755152892375040  1.671249e+12   \n",
            "3  1600151418346012673  1596741670686818304  1.670341e+12   \n",
            "4  1600148675606745090  1596741670686818304  1.670340e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-24 22:01:49    +0000         \n",
            "1  2022-12-21 19:06:29    +0000         \n",
            "2  2022-12-17 03:43:31    +0000         \n",
            "3  2022-12-06 15:33:22    +0000         \n",
            "4  2022-12-06 15:22:28    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0  @Itishree001 @YogaofKnowledge Modhera Sun Temp...       en       []   \n",
            "1  @mailkashyap2002 @Kalvapalle @shukla_tarun @In...       en       []   \n",
            "2  @jeffrey3333333 @natureisbruta1 His back broke...       en       []   \n",
            "3  @waqasnsp @trinitycosmo293 @hemalpandya1983 @A...       en       []   \n",
            "4  @waqasnsp @trinitycosmo293 @hemalpandya1983 @A...       en       []   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0  [{'screen_name': 'Itishree001', 'name': 'Itish...                          \n",
            "1  [{'screen_name': 'mailkashyap2002', 'name': 'L...                          \n",
            "2  [{'screen_name': 'jeffrey3333333', 'name': 'Je...                          \n",
            "3  [{'screen_name': 'waqasnsp', 'name': 'Waqas Na...                          \n",
            "4  [{'screen_name': 'waqasnsp', 'name': 'Waqas Na...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for SachinDPatange ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for Sunishen ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for tarunsharma005 ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1606499965840547843  1606252642644004864  1.671854e+12   \n",
            "1  1605031847146070016  1604697820279099392  1.671504e+12   \n",
            "2  1604764311993585669  1604531834196733952  1.671441e+12   \n",
            "3  1603230081568034816  1603055647989567489  1.671075e+12   \n",
            "4  1603026046248357888  1602669996588650498  1.671026e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-24 04:00:13    +0000         \n",
            "1  2022-12-20 02:46:27    +0000         \n",
            "2  2022-12-19 09:03:21    +0000         \n",
            "3  2022-12-15 03:26:52    +0000         \n",
            "4  2022-12-14 13:56:06    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0                     @raani_purohit Vrindavan, U.P.       nl       []   \n",
            "1  @afzal_congress ‡§™‡§†‡§æ‡§® ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§ï‡§æ ‡§π‡•Ä‡§∞‡•ã ‡§î‡§∞ ‡§π‡•Ä‡§∞‡•ã‡§á‡§® ‡§¶...       hi       []   \n",
            "2  @WasiuddinSiddi1 @SRKUniverse @SRKFC_PUNE @iam...      qme       []   \n",
            "3  @PragyaLive @iamsrk @deepikapadukone ‡§Æ‡•Ç‡§∞‡•ç‡§ñ, ‡§¶‡•á...       hi       []   \n",
            "4  @vivekagnihotri ‡§á‡§∏‡§ï‡•ã ‡§®‡§∂‡§æ ‡§Æ‡•Å‡§ï‡•ç‡§§‡§ø ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§∏‡•á ‡§¨‡§æ‡§π‡§∞...       hi       []   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0  [{'screen_name': 'raani_purohit', 'name': '‡§∞‡§æ‡§®...                          \n",
            "1  [{'screen_name': 'afzal_congress', 'name': 'Af...                          \n",
            "2  [{'screen_name': 'WasiuddinSiddi1', 'name': 'W...                          \n",
            "3  [{'screen_name': 'PragyaLive', 'name': 'Pragya...                          \n",
            "4  [{'screen_name': 'vivekagnihotri', 'name': 'Vi...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for dschamyal ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1609150050873282562  1609150050873282562  1.672486e+12   \n",
            "1  1609089762606088192  1609089762606088192  1.672472e+12   \n",
            "2  1608523444379090944  1608456929424310272  1.672337e+12   \n",
            "3  1608514731526197249  1608514731526197249  1.672335e+12   \n",
            "4  1608513426388844544  1608341618993811458  1.672334e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-31 11:30:43    +0000         \n",
            "1  2022-12-31 07:31:09    +0000         \n",
            "2  2022-12-29 18:00:48    +0000         \n",
            "3  2022-12-29 17:26:11    +0000         \n",
            "4  2022-12-29 17:21:00    +0000         \n",
            "\n",
            "                                               tweet language        hashtags  \\\n",
            "0  @abhivalimbe you need to see this complete thr...       en              []   \n",
            "1  Shame on you @TOIIndiaNews üò† Don't you know th...       en  [timesofindia]   \n",
            "2              @kamaalrkhan  https://t.co/ocbceBvBtl      qme              []   \n",
            "3                                        #LifeLesson      qht    [lifelesson]   \n",
            "4                          @krishnaeyee #Poltergeist      qme   [poltergeist]   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0                                                 []                          \n",
            "1                                                 []                          \n",
            "2                                                 []                          \n",
            "3                                                 []                          \n",
            "4  [{'screen_name': 'krishnaeyee', 'name': 'Krish...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for bhattketan1468 ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for roshovani ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for IndiaFirst2022 ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for DrBharatbhushan ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for abhiawakes ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for ShekharrG ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1609254934805110792  1609125054788554754  1.672511e+12   \n",
            "1  1609254392712298496  1609103322077868033  1.672511e+12   \n",
            "2  1609253604833234944  1609240593040920579  1.672511e+12   \n",
            "3  1608058340176965634  1607719519996497921  1.672226e+12   \n",
            "4  1607756189244477441  1607755534798815232  1.672154e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-31 18:27:29    +0000         \n",
            "1  2022-12-31 18:25:20    +0000         \n",
            "2  2022-12-31 18:22:12    +0000         \n",
            "3  2022-12-28 11:12:39    +0000         \n",
            "4  2022-12-27 15:12:00    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0  @SupriyaShrinate Agar isko shahadat aur shahee...       hi       []   \n",
            "1    @_sayema What's the religion of the terrorists?       en       []   \n",
            "2  @OpIndia_in @InnovativeHindu Apne bal katne ka...       hi       []   \n",
            "3  @tavleen_singh Any action taken on Sar Tan se ...       en       []   \n",
            "4  @Republic_Bharat This very same Shekhar Suman ...       en       []   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0  [{'screen_name': 'SupriyaShrinate', 'name': 'S...                          \n",
            "1  [{'screen_name': '_sayema', 'name': 'Sayema', ...                          \n",
            "2  [{'screen_name': 'OpIndia_in', 'name': '‡§ë‡§™‡§á‡§Ç‡§°‡§ø...                          \n",
            "3  [{'screen_name': 'tavleen_singh', 'name': 'Tav...                          \n",
            "4  [{'screen_name': 'Republic_Bharat', 'name': '‡§∞...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for VickyHanumant ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1606158871298338816  1606158871298338816  1.671773e+12   \n",
            "1  1598497258974367746  1598323612959776768  1.669946e+12   \n",
            "2  1595593169202466817  1595593169202466817  1.669254e+12   \n",
            "3  1594867166268252160  1594583400588800000  1.669081e+12   \n",
            "4  1594867075616735235  1594563759137120256  1.669081e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-23 05:24:50    +0000         \n",
            "1  2022-12-02 02:00:19    +0000         \n",
            "2  2022-11-24 01:40:30    +0000         \n",
            "3  2022-11-22 01:35:38    +0000         \n",
            "4  2022-11-22 01:35:16    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0  @ICICIBank_Care I have ordered a phone from Am...       en       []   \n",
            "1  @AJEnglish You don't have to worry about this....       en       []   \n",
            "2                                     @sagarikaghose      qam       []   \n",
            "3                              @AbhishBanerj @MnshaP      qam       []   \n",
            "4  @newslaundry @MnshaP Haa bilkul jaise tune jun...       et       []   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0                                                 []                          \n",
            "1  [{'screen_name': 'AJEnglish', 'name': 'Al Jaze...                          \n",
            "2                                                 []                          \n",
            "3  [{'screen_name': 'AbhishBanerj', 'name': 'Abhi...                          \n",
            "4  [{'screen_name': 'newslaundry', 'name': 'newsl...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for bhanuvarma007 ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for ScorpionHere ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for MohanKumarL11 ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for _hamza_iftikhar ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for Ksharkhowa ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1571924830991294466  1571779365855457287  1.663611e+12   \n",
            "1  1571923095098888192  1571779365855457287  1.663611e+12   \n",
            "2  1571922109626208256  1571779365855457287  1.663610e+12   \n",
            "3  1571917386214961152  1571779365855457287  1.663609e+12   \n",
            "4  1571895788330184704  1571479790883946500  1.663604e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-09-19 18:10:59    +0000         \n",
            "1  2022-09-19 18:04:05    +0000         \n",
            "2  2022-09-19 18:00:10    +0000         \n",
            "3  2022-09-19 17:41:24    +0000         \n",
            "4  2022-09-19 16:15:35    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0  @_atma @LiveLawIndia Followers of Hinduism har...       en       []   \n",
            "1  @_atma @LiveLawIndia The same way as places gi...       en       []   \n",
            "2  @_atma @LiveLawIndia Same argument as how Indi...       en       []   \n",
            "3  @LiveLawIndia Hindusim gave birth to India/Bha...       en       []   \n",
            "4  @grumbleagrumble @Birthday_Chris @IndigenousIn...       en       []   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0  [{'screen_name': '_atma', 'name': 'Antaratma',...                          \n",
            "1  [{'screen_name': '_atma', 'name': 'Antaratma',...                          \n",
            "2  [{'screen_name': '_atma', 'name': 'Antaratma',...                          \n",
            "3  [{'screen_name': 'LiveLawIndia', 'name': 'Live...                          \n",
            "4  [{'screen_name': 'grumbleagrumble', 'name': 'G...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for Nishwins1 ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1609154701878267904  1609154701878267904  1.672487e+12   \n",
            "1  1609129240422932481  1608869634878623746  1.672481e+12   \n",
            "2  1609061188813606914  1608682014760398848  1.672465e+12   \n",
            "3  1607958921817513985  1607599563602526209  1.672202e+12   \n",
            "4  1607628511384342529  1607628511384342529  1.672123e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-31 11:49:12    +0000         \n",
            "1  2022-12-31 10:08:01    +0000         \n",
            "2  2022-12-31 05:37:36    +0000         \n",
            "3  2022-12-28 04:37:36    +0000         \n",
            "4  2022-12-27 06:44:40    +0000         \n",
            "\n",
            "                                               tweet language        hashtags  \\\n",
            "0  This year will bring a reduction in limitation...       en  [happynewyear]   \n",
            "1                 @thyagarajan_law @memorable_90s No      und              []   \n",
            "2  @AbhinandhanMiG2 @DennisCricket_ Pant is a Bra...       en              []   \n",
            "3  @Hiraviews @majorgauravarya  https://t.co/qbuR...      qme              []   \n",
            "4  What a superb player Marco Jansen is, reminds ...       en       [ausvssa]   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0                                                 []                          \n",
            "1  [{'screen_name': 'thyagarajan_law', 'name': 'T...                          \n",
            "2  [{'screen_name': 'AbhinandhanMiG2', 'name': 'A...                          \n",
            "3  [{'screen_name': 'Hiraviews', 'name': 'Hira Vi...                          \n",
            "4                                                 []                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for PrasadSatya10 ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1609518794447417344  1609513944493981697  1.672574e+12   \n",
            "1  1609462852880060418  1609264252531138560  1.672561e+12   \n",
            "2  1609449578067275777  1609432223618588672  1.672558e+12   \n",
            "3  1609448511350923265  1609405799444664320  1.672557e+12   \n",
            "4  1609443570746023937  1609432223618588672  1.672556e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2023-01-01 11:55:58    +0000         \n",
            "1  2023-01-01 08:13:41    +0000         \n",
            "2  2023-01-01 07:20:56    +0000         \n",
            "3  2023-01-01 07:16:41    +0000         \n",
            "4  2023-01-01 06:57:03    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0                    @ians_india @Twitter Good show.       en       []   \n",
            "1          @Indrani1_Roy Wish you also a great 2023.       en       []   \n",
            "2  @EkNashwar @rushlane @Uber_India @Olacabs The ...       en       []   \n",
            "3  @mmpandey @mishra_abhi @PMOIndia @rajnathsingh...       en       []   \n",
            "4  @rushlane Congratulations. We more many more p...       en       []   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0  [{'screen_name': 'ians_india', 'name': 'IANS',...                          \n",
            "1  [{'screen_name': 'Indrani1_Roy', 'name': 'Indr...                          \n",
            "2  [{'screen_name': 'EkNashwar', 'name': '‡§è‡§ï ‡§®‡§∂‡•ç‡§µ...                          \n",
            "3  [{'screen_name': 'mmpandey', 'name': 'Man Moha...                          \n",
            "4  [{'screen_name': 'rushlane', 'name': 'RushLane...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for DiVpops ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for MiFe007 ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "======================================\n",
            ":: Acquiring Data for dcemeterygirl ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1608617990567911425  1608436773520302080  1.672359e+12   \n",
            "1  1603772498104893441  1603767815579635715  1.671204e+12   \n",
            "2  1603771765477343232  1603767896177790976  1.671204e+12   \n",
            "3  1603765942206746624  1603653595962171392  1.671203e+12   \n",
            "4  1603759964958621696  1603700597827698688  1.671201e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-30 00:16:30    +0000         \n",
            "1  2022-12-16 15:22:14    +0000         \n",
            "2  2022-12-16 15:19:20    +0000         \n",
            "3  2022-12-16 14:56:11    +0000         \n",
            "4  2022-12-16 14:32:26    +0000         \n",
            "\n",
            "                                               tweet language hashtags  \\\n",
            "0  @hvgoenka Losing every argument is the key to ...       en       []   \n",
            "1                @TajinderBagga 100 days ki mehnat üëé       en       []   \n",
            "2  @RupinderSra @timesofindia passed the baton* H...       in       []   \n",
            "3  @saikirankannan He is raking up Kashmir/Modi i...       en       []   \n",
            "4  @Birdman12369022 @wtfcsk @Nisha_NPU @ANI What ...       en    [end]   \n",
            "\n",
            "  cashtags  ...  geo source user_rt_id user_rt  retweet_id  \\\n",
            "0       []  ...                                              \n",
            "1       []  ...                                              \n",
            "2       []  ...                                              \n",
            "3       []  ...                                              \n",
            "4       []  ...                                              \n",
            "\n",
            "                                            reply_to retweet_date translate  \\\n",
            "0  [{'screen_name': 'hvgoenka', 'name': 'Harsh Go...                          \n",
            "1  [{'screen_name': 'TajinderBagga', 'name': 'Taj...                          \n",
            "2  [{'screen_name': 'RupinderSra', 'name': 'iamSr...                          \n",
            "3  [{'screen_name': 'saikirankannan', 'name': 'Sa...                          \n",
            "4  [{'screen_name': 'Birdman12369022', 'name': 'B...                          \n",
            "\n",
            "  trans_src  trans_dest  \n",
            "0                        \n",
            "1                        \n",
            "2                        \n",
            "3                        \n",
            "4                        \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "======================================\n",
            ":: Acquiring Data for citizenNA ::\n",
            "======================================\n",
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n",
            "                    id      conversation_id    created_at  \\\n",
            "0  1608562448268931072  1608562448268931072  1.672346e+12   \n",
            "1  1607854972003323904  1607854972003323904  1.672177e+12   \n",
            "2  1605075800939982853  1605075800939982853  1.671515e+12   \n",
            "3  1605075578410766336  1605075578410766336  1.671515e+12   \n",
            "4  1605075208888799233  1605075208888799233  1.671515e+12   \n",
            "\n",
            "                  date timezone place  \\\n",
            "0  2022-12-29 20:35:47    +0000         \n",
            "1  2022-12-27 21:44:32    +0000         \n",
            "2  2022-12-20 05:41:06    +0000         \n",
            "3  2022-12-20 05:40:13    +0000         \n",
            "4  2022-12-20 05:38:45    +0000         \n",
            "\n",
            "                                               tweet language  \\\n",
            "0                  RIP Pele  https://t.co/UO5OrGTkiK       en   \n",
            "1  Not just that Israel has no national cuisine, ...       en   \n",
            "2  It is not just Corbyn leadership that was targ...       en   \n",
            "3  The Israel Files: Wikileaks Docs Show Top Holl...       en   \n",
            "4  Is there a bigger Vile shitbag than you, @kelv...       en   \n",
            "\n",
            "                                  hashtags cashtags  ...  geo source  \\\n",
            "0                                       []       []  ...               \n",
            "1                                       []       []  ...               \n",
            "2  [keirstarmer, fordereport, labourparty]       []  ...               \n",
            "3                                       []       []  ...               \n",
            "4                             [nhsstrikes]       []  ...               \n",
            "\n",
            "  user_rt_id user_rt  retweet_id reply_to retweet_date translate trans_src  \\\n",
            "0                                      []                                    \n",
            "1                                      []                                    \n",
            "2                                      []                                    \n",
            "3                                      []                                    \n",
            "4                                      []                                    \n",
            "\n",
            "   trans_dest  \n",
            "0              \n",
            "1              \n",
            "2              \n",
            "3              \n",
            "4              \n",
            "\n",
            "[5 rows x 38 columns]\n"
          ]
        }
      ]
    }
  ]
}